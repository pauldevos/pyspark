{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b76a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_choice(lst):\n",
    "    return random.choice(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9d0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10000 lines in mnm_dataset.csv file\n"
     ]
    }
   ],
   "source": [
    "states = [\"CA\", \"WA\", \"TX\", \"NV\", \"CO\", \"OR\", \"AZ\", \"WY\", \"NM\", \"UT\"]\n",
    "colors = [\"Brown\", \"Blue\", \"Orange\", \"Yellow\", \"Green\", \"Red\"]\n",
    "fieldnames = ['State', 'Color', 'Count']\n",
    "\n",
    "\n",
    "entries = 10000\n",
    "dataset_fn = \"mnm_dataset.csv\"\n",
    "\n",
    "with open(dataset_fn, mode='w') as dataset_file:\n",
    "    dataset_writer = csv.writer(dataset_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dataset_writer.writerow(fieldnames)\n",
    "    for i in range(1, entries):\n",
    "        dataset_writer.writerow([get_random_choice(states), get_random_choice(colors), random.randint(10, 100)])\n",
    "print(\"Wrote %d lines in %s file\" % (entries, dataset_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19edd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77604c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1fb1f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/07 14:09:26 WARN Utils: Your hostname, Pauls-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.4.90 instead (on interface en0)\n",
      "22/06/07 14:09:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/07 14:09:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|NV   |Orange|47   |\n",
      "|CO   |Brown |80   |\n",
      "|WY   |Blue  |40   |\n",
      "|WA   |Brown |55   |\n",
      "|WA   |Orange|44   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|AZ   |Blue  |10938     |\n",
      "|WA   |Blue  |10789     |\n",
      "|CO   |Brown |10567     |\n",
      "|WY   |Brown |10419     |\n",
      "|WA   |Yellow|10150     |\n",
      "|UT   |Red   |10130     |\n",
      "|NV   |Orange|10079     |\n",
      "|AZ   |Orange|10060     |\n",
      "|TX   |Blue  |10023     |\n",
      "|TX   |Green |9984      |\n",
      "|NM   |Red   |9970      |\n",
      "|WY   |Green |9959      |\n",
      "|NM   |Yellow|9955      |\n",
      "|NM   |Blue  |9874      |\n",
      "|OR   |Blue  |9720      |\n",
      "|NV   |Yellow|9666      |\n",
      "|TX   |Brown |9597      |\n",
      "|WY   |Blue  |9572      |\n",
      "|AZ   |Green |9561      |\n",
      "|CO   |Yellow|9540      |\n",
      "|TX   |Yellow|9531      |\n",
      "|CO   |Blue  |9497      |\n",
      "|OR   |Red   |9429      |\n",
      "|CA   |Blue  |9422      |\n",
      "|WY   |Red   |9369      |\n",
      "|NV   |Blue  |9331      |\n",
      "|OR   |Yellow|9202      |\n",
      "|CA   |Red   |9134      |\n",
      "|OR   |Brown |9129      |\n",
      "|UT   |Orange|9069      |\n",
      "|WA   |Brown |9052      |\n",
      "|TX   |Red   |9050      |\n",
      "|AZ   |Red   |8966      |\n",
      "|UT   |Blue  |8883      |\n",
      "|NV   |Green |8853      |\n",
      "|OR   |Green |8845      |\n",
      "|OR   |Orange|8845      |\n",
      "|CA   |Green |8825      |\n",
      "|CA   |Brown |8779      |\n",
      "|NM   |Green |8762      |\n",
      "|WA   |Green |8740      |\n",
      "|CA   |Yellow|8719      |\n",
      "|AZ   |Yellow|8591      |\n",
      "|WA   |Red   |8559      |\n",
      "|WY   |Yellow|8559      |\n",
      "|UT   |Green |8557      |\n",
      "|WA   |Orange|8509      |\n",
      "|NV   |Brown |8496      |\n",
      "|CO   |Green |8472      |\n",
      "|CA   |Orange|8410      |\n",
      "|UT   |Yellow|8400      |\n",
      "|NV   |Red   |8382      |\n",
      "|CO   |Orange|8381      |\n",
      "|UT   |Brown |8378      |\n",
      "|NM   |Brown |8371      |\n",
      "|AZ   |Brown |8221      |\n",
      "|CO   |Red   |8086      |\n",
      "|TX   |Orange|8029      |\n",
      "|WY   |Orange|8002      |\n",
      "|NM   |Orange|6819      |\n",
      "+-----+------+----------+\n",
      "\n",
      "Total Rows = 60\n",
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Blue  |9422      |\n",
      "|CA   |Red   |9134      |\n",
      "|CA   |Green |8825      |\n",
      "|CA   |Brown |8779      |\n",
      "|CA   |Yellow|8719      |\n",
      "|CA   |Orange|8410      |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"PythonMnMCount\")\n",
    "    .getOrCreate())\n",
    "\n",
    "\n",
    "# read the file into a Spark DataFrame\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(dataset_fn))\n",
    "\n",
    "mnm_df.show(n=5, truncate=False)\n",
    "\n",
    "# aggregate count of all colors and groupBy state and color\n",
    "# orderBy descending order\n",
    "count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                .groupBy([\"State\", \"Color\"])\n",
    "                .sum(\"Count\")\n",
    "                .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show all the resulting aggregation for all the dates and colors\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "# find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df.select(\"*\")\n",
    "                   .where(mnm_df.State == 'CA')\n",
    "                   .groupBy(\"State\", \"Color\")\n",
    "                   .sum(\"Count\")\n",
    "                   .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show the resulting aggregation for California\n",
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b75d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark3_09]",
   "language": "python",
   "name": "conda-env-pyspark3_09-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
